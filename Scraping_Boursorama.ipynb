{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winnie VORIHILALA <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPING PYTHON DU SITE BOURSORAMA AVEC LA LIBRAIRIE REQUEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup, Tag\n",
    "import requests\n",
    "import datetime\n",
    "import xlsxwriter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'/Users/winnievorihilala/Documents/Midcap_partners/23-04-2020/DATASET_D2/D2_init.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des fonctions de nettoyage de textes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer_nom(s): \n",
    "    s = s.replace('Raison', '')\n",
    "    s = s.replace('sociale', '')\n",
    "    s = s.replace('Raison sociale', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace('  ', '')\n",
    "    return(s)\n",
    "def nettoyer_adresse(s): \n",
    "    #s = s.replace('\\n', '')\n",
    "    #s = s.replace('  ', '')\n",
    "    if 'Norvège' in s :\n",
    "        s = 'Norvège'\n",
    "    elif 'France' in s :\n",
    "        s = 'France'\n",
    "    elif 'Suisse' in s :\n",
    "        s = 'Suisse'\n",
    "    elif 'London' in s :\n",
    "        s = 'UK'\n",
    "    elif 'Espagne' in s :\n",
    "        s = 'Espagne'\n",
    "    elif 'Italie' in s :\n",
    "        s = 'Italie'\n",
    "    elif 'Belgique' in s :\n",
    "        s = 'Belgique'\n",
    "    elif 'Allemagne' in s :\n",
    "        s = 'Allemagne'\n",
    "    elif 'Danemark' in s :\n",
    "        s = 'Danemark'\n",
    "    elif 'Pays-Bas' in s :\n",
    "        s = 'Pays-Bas'\n",
    "    elif 'Suède' in s :\n",
    "        s = 'Suède'\n",
    "    elif 'Luxembourg' in s :\n",
    "        s = 'Luxembourg'\n",
    "    elif 'Royaume-Uni' in s :\n",
    "        s = 'UK'\n",
    "    elif 'Irlande' in s :\n",
    "        s = 'Irlande'\n",
    "    elif 'États-Unis' in s :\n",
    "        s = 'États-Unis'\n",
    "    return(s)\n",
    "def nettoyer_description(s): \n",
    "    s = s.replace('\\n', '')\n",
    "    return(s)\n",
    "def nettoyer_marketcap(s): \n",
    "    s = s.replace('Capitalisation', '')\n",
    "    s = s.replace('boursière', '')\n",
    "    s = s.replace('Capitalisation boursière', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace('  ', '')\n",
    "    return(s)\n",
    "def nettoyer_marche(s): \n",
    "    s = s.replace('Marché', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace('  ', '')\n",
    "    return(s)\n",
    "def nettoyer_titres(s): \n",
    "    s = s.replace('Nombre de titres', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace('  ', '')\n",
    "    return(s)\n",
    "def nettoyer_site(s): \n",
    "    s = s.replace('Site web', '')\n",
    "    s = s.replace('Site', '')\n",
    "    s = s.replace('Web', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace('  ', '')\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(0,df.shape[0]-1):\n",
    "    response = requests.get(df.iloc[i,0])\n",
    "    soup = Soup(response.content)\n",
    "    try:\n",
    "        description = str(soup.find('p', attrs = {'class':'o-ellipsis-multiline-6'}).text).strip()\n",
    "    except:\n",
    "        description = 'None'   \n",
    "    form_div = soup.find(\"div\", {\"class\": \"c-list-info c-list-info--no-gutter@md-min\"})\n",
    "    maliste = []\n",
    "    for item in form_div.findAll('li'):\n",
    "        if isinstance(item, Tag):\n",
    "            #print(item.text)\n",
    "            maliste.append(item.text)\n",
    "    nom = maliste[0]\n",
    "    siege_social = maliste[1]\n",
    "    site_web = maliste[2]\n",
    "    titres = maliste[5]\n",
    "    marketcap = maliste[6]\n",
    "    marche = maliste[7]\n",
    "    \n",
    "    nom = nettoyer_nom(nom)\n",
    "    siege_social = nettoyer_adresse(siege_social)\n",
    "    description = nettoyer_description(description)\n",
    "    marketcap = nettoyer_marketcap(marketcap)\n",
    "    marche = nettoyer_marche(marche)\n",
    "    titres = nettoyer_titres(titres)\n",
    "    site_web = nettoyer_site(site_web)\n",
    "\n",
    "    date=datetime.datetime.today().strftime('%d-%m-%Y')\n",
    "    data.append({'Date':date,'Nom':nom,'Siège social':siege_social,'Description':description,'Capitalisation boursière':marketcap,'Marché':marche,'Nombre de titres':titres,'Site web':site_web})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export sous format excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook(r'/Users/winnievorihilala/Documents/Midcap_partners/23-04-2020/DATASET_D2/Coverage_Midcap_Partners.xlsx')\n",
    "worksheet = workbook.add_worksheet('Coverage')\n",
    "bold = workbook.add_format({'bold': True})\n",
    "worksheet.write(0,0,'Date',bold)\n",
    "worksheet.write(0,1,'Nom',bold)\n",
    "worksheet.write(0,2,'Siège social',bold)\n",
    "worksheet.write(0,3,'Description',bold)\n",
    "worksheet.write(0,4,'Capitalisation boursière',bold)\n",
    "worksheet.write(0,5,'Marché',bold)\n",
    "worksheet.write(0,6,'Nombre de titres',bold)\n",
    "worksheet.write(0,7,'Site web',bold)\n",
    "\n",
    "for i in range(1,len(data)+1):\n",
    "    try:\n",
    "        worksheet.write(i,0,data[i-1]['Date'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,1,data[i-1]['Nom'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,2,data[i-1]['Siège social'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,3,data[i-1]['Description'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,4,data[i-1]['Capitalisation boursière'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,5,data[i-1]['Marché'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,6,data[i-1]['Nombre de titres'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        worksheet.write(i,7,data[i-1]['Site web'])\n",
    "    except:\n",
    "        pass\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
